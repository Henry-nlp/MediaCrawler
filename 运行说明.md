# 程序使用说明

## 爬虫设置

- ./config/base_config.py：设置爬虫平台，登录方式，爬取方式，搜索关键词
 ```shell
 PLATFORM = "xhs"
 KEYWORDS = "长征，长汀"  # 关键词搜索配置，以英文逗号分隔
 LOGIN_TYPE = "qrcode"  # qrcode or phone or cookie
 ENABLE_GET_COMMENTS：是否爬取评论，默认为False，如需爬取评论请设置为True
 CRAWLER_TYPE = (
    "search"  # 爬取类型，search(关键词搜索) | detail(帖子详情)| creator(创作者主页数据)
 )
 CRAWLER_MAX_NOTES_COUNT = 100  # 每次爬取帖子数量，不超过100
 ```

- 开始爬虫，在terminal中，进入路径 E:\code\MediaCrawler，执行以下命令
```shell  
# 从配置文件中读取关键词搜索相关的帖子并爬取帖子信息与评论
python main.py --platform xhs --lt qrcode --type search

# 打开对应APP扫二维码登录
   ```

## 数据保存
- 每次爬虫请求的数据存储于：./data/xhs/json/*.json

## 数据处理
- 处理代码./postprocess/xhs/postprocess.py：小红书数据后处理脚本，包括生成柱状图、词云等
```shell
# 在terminal中进入路径 E:\code\MediaCrawler，运行下列代码
python ./postprocess/xhs/postprocess.py
```

- 新增停用词
```shell
# 打开 config/base_config.py
# 添加规则：xx:yy 其中xx为自定义添加的词组，yy为将xx该词组分到的组名。
CUSTOM_WORDS = {
    "零几": "年份",  # 将“零几”识别为一个整体
    "高频词": "专业术语",  # 示例自定义词
}
```

## 处理结果

- 结果在路径 ./data/xhs/csv 和 ./data/xhs/words 查看


## 代码说明
- main.py：主程序入口，根据命令行参数选择对应的爬虫平台，并执行爬取操作
- base_config.py：设置待爬虫平台，登录方式设置，爬取方式，搜索关键词
- media_platform/xhs/core.py：小红书爬虫核心代码，包括登录、获取帖子信息、获取评论等操作
 - xhs_limit_count：设置每次爬取帖子数量，不超过“CRAWLER_MAX_NOTES_COUNT”

